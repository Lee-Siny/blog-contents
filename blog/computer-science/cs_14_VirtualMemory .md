---
title: "가상 메모리"
meta_title: "가상메모리"
description: "스와핑, 최초 적합, 최적 적합, 최악 적합, 외부 단편화, 페이징, 페이지 테이블, PTBR, TLB, 요구 페이징, 페이지 교체 알고리즘, 스래싱, 프레임 할당"
date: 2024-02-28T10:08:06+09:00
image: "/images/cs.svg"
categories: ["Computer-Science"]
author: "Sinyoung Lee"
tags: ["Computer-Science"]
draft: false
---

# **연속 메모리 할당**  
프로세스에 연속적인 메모리를 할당하는 방식  
=> 프로세스 A는 A의 크기만큼 메모리 주소를 할당받아 연속적으로 배치되고, 프로세스 B는 프로세스 A 이후에 B의 크기만큼 연속적인 메모리 주소를 할당받아 배치되는 방식  

{{< callout type="info" >}}  
연속 메모리 할당의 문제점  
- 외부 단편화  
- 물리 메모리보다 큰 프로세스를 실행 할 수 없음  
{{< /callout >}}  

<br>
<hr>

## **스와핑(swapping)**  
메모리에서 사용하지 않거나, 계속 대기 중인 프로세스를 메모리에서 보조기억장치 일부 영역으로 내보내고, 그렇게 해서 생긴 메모리상의 빈 공간에 또 다른 프로세스를 적재하여 실행하는 방식  

{{< callout type="info" >}}  
스와핑을 이용하면 프로세스들이 요구하는 메모리 주소 골간의 크기가 실제 메모리 크기보다 큰 경우에도 프로세스들을 동시 실행할 수 있음  
{{< /callout >}}  

<br>

### **스왑 영역(swap space)**  
프로세스들이 쫒겨나는 보조기억장치의 일부 영역  

<br>

### **스왑 아웃(swap-out)**  
현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것  

<br>

### **스왑 인(swap-in)** 
스왑 영역에 있던 프로세스가 다시 메모리로 옮겨오는 것  

{{< callout type="info" >}}  
스왑 아웃 되었던 프로세스가 다시 스왑 인될 때는 스왑 아웃되기 전의 물리 주소와는 다른 주소에 적재될 수 있음  
{{< /callout >}}  

<br>
<hr>

## **연속적 메모리 할당**  
비어 있는 메모리 공간에 프로세스를 연속적으로 할당하는 방식  
(프로세스는 메모리 내의 빈 공간에 적재되어야 함)  

<br>

### **최초 적합(first fit)**  
운영체제가 메모리 내의 빈 공간을 순서대로 검색하다가 적재할 수 있는 공간을 발견하면 그 공간에 프로세스를 배치하는 방식  
(프로세스가 적재될 수 있는 공간을 발견하는 즉시 메모리를 할당하는 방식)  
=> 검색이 최소화되며, 빠르게 할당할 수 있음  

<br>

### **최적 적합(best fit)**  
운영체제가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 작은 공간에 프로세스를 배치하는 방식  
=> 남는 공간이 가장 작은 공간에 배치하기 때문에 가장 최적임  

<br>

### **최악 적합(worst fit)**  
운영체제가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 큰 공간에 프로세스를 배치하는 방식  
=> 남는 공간이 가장 큰 공간에 배치하기 때문에 가장 아까움  

<br>
<hr>

## **외부 단편화(external fragmentation)**  
프로세스를 할당하기 어려울 만큼 작은 메모리 공간들로 인해 메모리가 낭비되는 현상  
(연속 메모리 할당이 내포하고 있는 문제 => 외부 단편화)  

> - 프로세스들이 메모리에 연속적으로 할당되고 종료되는 과정을 반복  
> - 프로세스 사이에 빈 메모리 공간이 생김  
> - 빈 메모리 공간을 합쳐서 보면 충분한 공간이지만, 프로세스를 적재할 수 없는 상황 = 외부 단편화  
> => 메모리의 합공간은 충분하지만, 실제로는 공간이 분리되어 있기 때문에 큰 프로세스를 적재하기 어려움  
> - 메모리 낭비  

<br>

### **압축**  
메모리 내에 저장된 프로세스를 적당히 재배치시켜서 픛어져 있는 작은 빈공간들을 하나의 큰 빈공간으로 만드는 방식  
(외부 단편화를 해결하는 방법)  

#### **압축의 단점**  
- 작은 빈 공간들을 하나로 모으는 동안 시스템은 하던 일을 중지해야함  
- 메모리에 있는 내용을 옯기는 과정에서 많은 오버헤드가 야기됨  
- 어떤 프로세스를 어떻게 움직여야 오버헤드를 최소화하며 압축할 수 있는지에 대한 명확한 방법을 결정하기 어려움  

{{< callout type="info" >}}  
외부 단편화를 없앨 수 있는 또 다른 해결 방안이 등장  
=> 가상 메모리 기법 중 페이징 기법  
{{< /callout >}}  

<br>
<hr>

# **페이징을 통한 가상 메모리 관리**  
**가상 메모리(virtual Memory)**  
실행하고자 하는 프로그램을 일부만 메모리에 적재하여 실제 물리적 메모리의 크기보다 더 큰 프로세스를 실행할 수 있게 해 주는 기술  

가상 메모리 관리 기법에는 크게 페이징, 세그멘테이션이 있지만, 연대 대부분의 운영체제가 사용하는 기법은 페이징 기법임  
=> 페이징 기법을 이용하면 물리 메모리보다 큰 프로세스를 실행할 수 있고, 외부 단편화 문제도 해결 할 수 있음  

<br>
<hr>

## **페이징(paging)**  
메모리의 물리 주소 공간을 프레임 단위로 자르고, 프로세스의 논리 주소 공간을 페이지 단위로 자른 뒤 각 페이지를 프레임에 할당하는 가상 메모리 관리 기법  

{{< callout type="info" >}}  
한 프로세스를 실행하기 위해 프로세스 전체가 메모리에 적재될 필요가 없음  

프로세스를 이루는 페이지 중 실행에 필요한 일부 페이지만을 메모리에 적재하고, 당장 실행에 필요하지 않은 페이지들은 보조기억장치에 남겨둘 수 있음  
=> 물리 메모리보다 더 큰 프로세스를 실행할 수 있음  
{{< /callout >}}  

<br>

### **페이징에서의 스와핑**  
페이지 단위로 스왑 아웃/스왑 인 됨  

<br>

#### **페이지 아웃(page-out)**  
메모리에 적재될 필요가 없는 페이지들은 보조기억장치로 스왑 아웃  

<br>

#### **페이지 인(page-in)**  
실행에 필요한 페이지들은 메모리로 스왑 인  

<br>
<hr>

## **페이지 테이블**  
> 프로세스가 물리적 메모리에 불연속적으로 배치되어 있을 경우, CPU 입장에서는 이를 순차적으로 실행할 수 없음  
> 프로세스를 이루는 페이지가 어느 프레임에 적재되어 있는지 CPU가 모두 알고 있는 것은 어렵기 때문  
> 즉, 프로세스가 메모리에 불연속적으로 배치되면 CPU 입장에서는 ‘다음에 실행할 명령어 위치’를 알기 어려워짐  

페이징 시스템은 프로세스가 비록 실제 메모리 내의 주소인 물리적 주소에 불연속적으로 배치되더라도, CPU가 바라보는 주소인 논리적 주소에는 연속적으로 배치되도록 페이지 테이블을 이용  
=> 실제 메모리 물리 주소에서는 불연속적이더라도 CPU가 바라보는 논리 주소에는 연속적으로 배치되도록 하는 것이 페이지 테이블  

{{< callout type="info" >}}  
프로세스마다 페이지 테이블을 가지고 있음  
프로세스의 논리 주소 공간을 페이지라는 일정한 단위로 자름  
메모리 물리 주소 공간을 프레임이라는 페이지와 동일한 크기의 단위로 자름  

=> 페이지 테이블의 페이지 번호를 이용해 페이지가 적재된 프레임을 찾을 수 있음  
{{< /callout >}} 

{{< callout type="info" >}}  
프로세스마다 각자의 프로세스 테이블을 가지고 있고 각 프로세스의 페이지 테이블들은 메모리에 적재되어 있음

각 프로세스들의 페이지 테이블 정보들은 각 프로세스의 PCB에 기록됨  
(프로세스의 문맥 교환이 일어날 때 다른 레지스터와 마찬가지로 함께 변경됨)  
{{< /callout >}} 

<br>

### **내부 단편화(internal fragmentation)**  
프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비되는 현상  
=> 페이징은 프로세스의 논리 주소 공간을 페이지라는 일정한 크키 당위로 자르지만, 모든 프로세스가 페이지 크기에 딱 맞게 잘리는 것이 아님  
(= 모든 프로세스의 크기가 페이지 크기의 배수가 아님)  

> 페이지 크기를 잘게 자르면 자를수록 내부 단편화를 줄일 수 있지 않을까?  
> &nbsp; 하나의 페이지 크기가 작다면 발생하는 내부 담현화의 크디는 작아질 것으로 기대할 수 있음  
> 하지만,  
> &nbsp; 하나의 페이지 크기를 너무 작게 설정하면 그만큼 페이지 테이블의 크기도 커지기 때문에 페이지 테이블이 차지하는 공간이 낭비됨  
> &nbsp; + 페이지 테이블의 크기가 늘어나 유지 비용이 많이 들 수 있음  

<br>

### **페이지 테이블 베이스 레지스터**  
**(PTBR : Page Table Base Register)**  
CPU 내에서 각 프로세스의 페이지 테이블이 적재된 주소를 가리킴  
=> CPU는 PTBR을 통해 각 프로세스들의 페이지 테이블이 어디에 저장되어 있는지를 알 수 있음  

<br>

### **페이지 테이블 캐시 메모리**  
**(TLB : Translation Lookaside Buffer)**  
CPU 곁에 (MMU 내에)있는 페이지 테이블의 캐시 메모리  
=> 페이지 테이블의 캐시 메모리 역할을 수행하기 위해 페이지 테이블의 일부를 저장  
=> 참조 지역성에 근거해 주로 최근에 사용된 페이지 위주로 가져와 저장  

> 페이지 테이블이 메모리에 있으면 CPU의 메모리 접근 시간이 두배로 늘어남  
> 메모리에 있는 페이지 테이블을 보기 위해 한 번, 그렇게 알게 된 프레임에 접근하기 위해 한번, 총 두 번의 메모리 접근이 필요  
>
> => CPU 곁에 (MMU 내에) TLB라는 페이지 테이블의 캐시 메모리를 두어 해결  

<br>

#### **TLB 히트(TLB hit)**  
논리 주소에 대한 페이지 번호가 TLB에 있는 경우  
=> 페이지가 적재된 프레임을 아기 위해 메모리에 접근할 필요가 없음  
=> 메모리 접근을 한 번만 하면 됨  

<br>

#### **TLB 미스(TLB miss)**  
논리 주소에 대한 페이지 번호가 TLB에 없는 경우  
=> 페이지가 적재된 프레임을 알기 위해 메모리 내의 페이지 테이블에 접근 해야함  
-> 메모리 접근을 두 번 해야함  

<br>
<hr>

## **페이징에서의 주소 변환**  
페이징 시스템에서의 논리 주소는 페이지 테이블을 통해 물리 주소로 변환됨  

> 페이징을 사용하는 시스템에서 특정 주소로 접근하기 위해서는 2가지 정보가 필요  
> - 어떤 페이지 혹은 프레임에 접근하고 싶은지  
> - 접근하려는 주소가 그 페이지 혹은 프레임으로부터 얼마나 떨어져 있는지  

> 페이징 시스템에서의 모든 논리 주소  = 페이지 번호(page number) + 변위(offest)  
> => 논리주소 <페이지 번호, 변위> = 물리주소 <프레임 번호, 변위>

### **페이지 번호(page number)**
접근하고자 하는 페이지 번호
=> 페이지 테이블에서 해당 페이지 번호를 찾으면 페이지가 어떤 프레임에 할당되었는지를 알 수 있음

### **변위(offest)**  
접근하려는 주소가 프레임의 시작 번지로부터 얼만큼 떨어져 있는지를 알기 위한 정보  

<br>
<hr>

## **페이지 테이블 엔트리**  
**(PTE : Page Table Entry)**  
페이지 테이블의 각 행
=> 페이지 번호, 프레임 번호, 유효 비트, 보호 비트, 참조 비트, 수정 비트 등  

<br>

### **유효 비트(valid bit)**  
현재 페이지가 메모리에 적재되어 있는지, 보조기억장치에 있는지를 알려주는 비트  
=> 페이지가 메모리에 적재되어 있다면 유효 비트 1, 페이지가 메모리에 적재되어 있지 않다면 유효 비트 0  

> CPU가 유효 비트가 0인 메모리에 적재되어 있지 않은 페이지로 접근하려고 하면?  
> (페이지가 보조기억장치(스왑 영역)에 있는 경우는 메모리에 적재되어 있기 않기 
때문에 접근 불가)  
> **페이지 폴트(page fault) 인터럽트** 발생  

> **CPU의 페이지 폴트 처리과정**  
> 1. CPU는 기존의 작업 내역을 백업  
> 2. 페이지 폴트 처리 루틴을 실행  
> 3. 페이지 처리 루틴은 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경  
> 4. 페이지 폴트를 처리했다면, 이제 CPU는 해당 페이지에 접근할 수 있게 됨  

<br>

### **보호 비트(protection bit)**  
페이지 접근 권한을 제한하여 페이지를 보호하는 비트  
=> 읽기(Read) r, 쓰기(Write) w, 실행(eXcute) x : 3개의 비트로 접근 권한을 제어  

<br>

### **참조 비트(reference bit)**  
CPU가 이 페이지에 접근한 적이 있는지의 여부를 알려주는 비트  
=> 적재 이후 CPU가 읽거나 쓴 페이지는 참조 비트 1, 적재 이후 한 번도 읽거나 쓴 적이 없는 페이지는 참조 비트 0  

<br>

### **수정 비트(modified bit)**
**(= 더티 비트(dirty bit))**  
CPU가 해당 페이지의 데이터를 쓴 적이 있는지의 없는지 수정 여부를 알려주는 비트  
=> 변경된 적이 있는 페이지는 수정 비트 1, 변경된 적이 없는 페이지는 수정 비트 0  

> 수정 비트는 이 페이지가 메모리에서 사라질 때 보조기억장치에서 쓰기 작업을 해야 하는지를 판정하기 위해 필요  
> 
> CPU가 데이터를 작성하지 않았다면 보조기억장치와 메모리에 있는 내용은 서로 같을 것  
> => 한 번도 수정된 적이 없는 페이지가 스왑 아웃될 경우에는 추가 작업 없이 새로 적재된 페이지로 덮어쓰기만 하면 됨  
>
> CPU가 쓰기 작업을 한 경우
> => 두 내용이 서로 다르기 때문에 수정된 적이 있는 페이지가 스왑 아웃 될 경우에는 변경된 값을 보조기억장치에 기록하는 작업이 추가되어야 함  
>
> => 이런 일련의 작업이 필요한 페이지인지 아닌지를 판단하기 위해 페이지 테이블 엔트리에 수정 비트를 두는 것임  

<br>
<hr>

# **페이지 교체와 프레임 할당**  
페이징 기법을 활용하여 물리적 메모리보다 큰 프로세스를 실행할 수 있다고 했으나, 그럼에도 불구하고 물리적 메모리의 크기는 한정되어 있음  
=> 즉, 한 번에 매우 많은 프로세스를 실행할 수는 없음  

> 운영체제는 프로세스들이 한정된 메모리를 효율적으로 이용할 수 있도록 기존에 메모리에 적재된 불필요한 페이지를 선별하여 보조기억장치로 내보낼 수 있어야함(페이지 교체)  
> 프로세스들에 적절한 수의 프레임을 할당하여 페이지를 할당할 수 있어야함(프레임 할당)  

<br>

## **요구 페이징(demand paging)**  
프로세스를 메모리에 적재할 때 처음부터 모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 기법  

> 1. CPU가 특정 페이지에 접근하는 명령어를 실행  
> 2. 해당 페이지가 현재 메모리에 있을 경우 (유효 비트가 1일 경우), CPU는 페이지가 적재된 프레임에 접근  
> 3. 해당 페이지가 현재 메모리에 없을 경우 (유효 비트가 0일 경우), 페이지 폴트가 발생  
> 4. 페이지 폴트 처리 루틴은 해당 페이지를 메모리로 적재하고, 유효 비트를 1로 설정  
> => (즉, 요구 페이징은 페이지가 필요할 때 에만 메모리에 적재)  
> 5. 다시 1을 수행  

<br>

### **순수 요구 페이징(pure demand paging)**  
아무런 페이지도 적재되어 있지 않은 채 실행부터 하도록 하는 것  
=> 페이지가 없기 때문에 프로세스의 첫 명령어를 실행하는 순간부터 페이지 폴트가 계속 발생하게 되고, 실행에 필요한 페이지가 어느 정도 적재된 이후부터는 페이지 폴트 발생 빈도가 떨어짐  

<br>
<hr>

## **페이지 교체**
요구 페이징 기법으로 페이지들을 적재하다 보면 언젠가 물리적 메모리 용량을 초과하게 됨  
=> 이 경우 당장 실행에 필요한 페이지를 적재하기 위해 메모리에 적재된 페이지를 보조기억장치로 내보내야함  

이때, 메모리에 적재된 많고 많은 페이지 중 어떤 페이지를 내보내는 것이 최선인지 결정해야함  
=> 이를 결정하는 방법 = 페이지 교체 알고리즘  

<br> 

### **페이지 교체 알고리즘**  
페이지 폴트 횟수가 적을수록 좋은 페이지 교체 알고리즘임  
=> 페이지 폴트가 일어나면 보조기억장치들로부터 필요한 페이지를 가져와야 하기 때문에 메모리에 적재된 페이지를 가져오는 것보다 느려지기 때문  

> 이곳에 설명된 페이지 교체 알고리즘 이외에도 더 많은 페이지 교체 알고리즘이 있음  

<br> 

### **페이지 참조열(page reference string)**  
CPU가 참조하는 페이지들 중 연속된 페이지를 생략한 페이지열  
=> 페이지 참조열을 통해 페이지 폴트 횟수를 알 수 있음  

> CPU가 2 2 2 3 5 5 5 3 3 7 과 같은 순서로 페이지에 접근
> 페이지 참조열 = 2 3 5 3 7
>
> 중복된 페이지를 생략한 이유는 페이지 폴트 처리 루틴이 끝난 뒤 다시 접근하기 때문에 페이지 폴트가 발생할 이유가 없기 때문
> => 즉, 페이지 교체 알고리즘의 성능을 측정하는 데 관련이 없음  

<br> 

### **FIFO 페이지 교체 알고리즘**  
**(First-In First-Out Page Replacement Algorithm)**  
메모리에 적재된 페이지 순서대로 교체하는 알고리즘  
=> 메모리에 가장 먼저 올라온 페이지부터 내쫓는 방식

장점 : 가장 단순한 방법, 구현 간단  
단점 : 효율 낮음
한계 : 실행 초기에 적재된 페이지 속 프로그램 실핸 내내 사용될 내용을 포함하고 있는 경우 => 메모리에 먼저 적재되었다고 해서 교체시키면 안됨  

<br> 

### **2차 기회 페이지 교체 알고리즘**
**(second chance Page Replacement Algorithm)**  
CPU가 한 번 참조한 적이 있던 페이지라면 바로 내쫓지 않고 적재된 시간을 현재 시간으로 설정하고 맨 끝으로 보내는 알고리즘  
(FIFO 페이지 알고리즘 + 페이지의 참조 비트)  
=> 기본적으로는 FIFO 페이지 교체 알고리즘의 원칙 (오래 머무른 것을 내쫓는)을 따름, 그런데 참조된 적이 있다면 기회를 한번 더 줌  

<br> 

### **최적 페이지 교체 알고리즘**
**(Optimal Page Replacement Algorithm)**  
앞으로의 사용 빈도가 가장 낮은 페이지를 교체하는 알고리즘  
(CPU에 의해 참조되는 횟수를 고려하는 페이지 교체 알고리즘)  

장점 : 가장 낮은 페이지 폴트율을 보장하는 알고리즘  
단점 : 구현이 어려움  
한계 : 미래를 기준으로 판단하기 때문에 비현실적  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; => 프로세스가 앞으로 메모리 어느 부분을 어떻게 참조할지 미리 알 방법은 현실적으로 불가능에 가까움   

**사용**  
최적 페이지 교체 알고리즘을 실행했을 때 발생하는 페이지 폴트 횟수를 페이지 폴트의 하한선으로 간주  
=> 최적 페이지 교체 알고리즘에 비해 얼만큼 페이지 폴트 횟수가 발생하느냐를 통해 페이지 교체 알고리즘을 평가하기 위해 사용  

<br> 

### **LRU 페이지 교체 알고리즘**  
**(Least Recently Used Page Replacement Algorithm)**  
가장 오랫동안 사용되지 않은 페이지를 교체하는 알고리즘  

<br> 
<hr>

## **페이지 폴트의 빈도 높은 발생 이유**  
페이지 폴트가 자주 발생하는 이유  
- 나쁜 페이지 교체 알고리즘 사용  
- 프로세스가 사용할 수 있는 프레임 자체가 적음  
  => 반대로 프로세스가 사용할 수 있는 프레임 수가 많으면 일반적으로 페이지 폴트 빈도는 감소  

프레임이 부족하면 CPU가 페이지 폴트가 자주 발생할 수 밖에 없음  
=> 실행의 맥이 탁 탁 끊기고, 결과적으로 CPU의 이용률도 떨어짐  
=> 페이지 폴트가 자주 발생할수록 페이지 폴트를 해결하는 데 드는 시간이 증가되기 때문  

<br>

## **스레싱(thrashing)**  
프로세스가 실행되는 시간보다 페이징에 더 많은 시간을 소요하여 성능이 저하되는 문제  
(지나치게 빈번한 페이지 교체로 인해 CPU이용률이 낮아지는 문제)  

**스레싱 발생 이유**  
각 프로세스가 필요로 하는 최소한의 프레임 수가 보장되지 않았기 때문  

**스레싱 해결**  
각 프로세스가 필요로 하는 최소한의 프레임 수를 파악하여 프로세스들에게 적절한 프레임을 할당해주어야함  

<br>

## **프레임 할당 방식**  

### **정적 할당 방식**  
프로세스의 실행 과정을 고려하지 않고 단순히 프로세스의 크기와 물리적 메모리의 크기만을 고려한 방식  

#### **균등 할당(equal allocation)**  
가장 단순한 할당 방식으로써, 모든 프로세스들에게 균등하게 프레임을 할당하는 방식  
=> 그다지 권장하지 않는 방식, 프로세스의 크기가 각기 다른데 고려하지 않았기 때문  

#### **비례 할당(proportional allocation)**  
프로세스 크기를 고려하여 프레임을 할당하는 방식  
(프로세스 크기가 크면 많은 프레임을, 작으면 적은 프레임을 할당)  
=> 크기가 큰 프로세스인데 막상 실행해보니 많은 프레임을 필요로 하거나, 
크기가 작은 프로세스인데 막상 실행해보니 많은 프레임을 필요로 할 수 있음  
=> 결국, 프로세스가 필요로 하는 프레임 수는 실행해봐야 알 수 있음  

<br>

### **동적 할당 방식**  
프로세스를 실행하는 과정에서 배분할 프레임을 결정하는 방식  

#### **작업 집합 모델(working set model)**  
작업 집합의 크기만큼만 프레임을 할당하는 방식  
(작업 집합 : 실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합)  

스래싱이 발생하는 이유 = 빈번한 페이지 교체 때문  
=> 프로세스가 일정 기간 동안 참조한 페이지 집합을 기억하여 빈번한 페이지 교체 방지  
=> CPU가 특정 시간 동안 주로 참조한 페이지를 작업 집합에 포함한다면,운영체제는 작업 집합의 크기만큼만 프레임 할당  

#### **페이지 폴트 빈도(PFF: Page-Falut Frequency)**  
페이지 폴트율에 상한선과 하한선을 정하고, 그 내부 범위 안에서반 프레임을 할당하는 방식  

- 페이지 폴트율이 높으면 그 프로세스는 너무 적은 프레임을 갖고 있음  
- 페이지 폴트율이 낮으면 그 프로세스는 너무 많은 프레임을 갖고 있음
=> 페이지 폴트율에 상한선과 하한선을 정하고, 그 내부 범위 안에서만 프레임 할당  


<br>
<hr>

> 참고  
> [혼자 공부하는 컴퓨터 구조+운영체제 (책)](https://hongong.hanbit.co.kr/%EC%BB%B4%ED%93%A8%ED%84%B0-%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/)  
> [혼자 공부하는 컴퓨터 구조+운영체제 (강의)](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C)


