---
title: "메모리와 캐시메모리"
meta_title: "메모리와 캐시메모리 "
description: "RAM, Memory Adderss, Cash Memory"
date: 2024-01-05T10:21:17+09:00
image: "/images/cs.svg"
categories: ["Computer-Science"]
author: "Sinyoung Lee"
tags: ["Computer-Science"]
draft: false
---

# **RAM의 특징과 종류**  
주기억장치 : RAM, ROM  
=> Memory = RAM  

{{< callout type="info" >}}  
**RAM**  
Random Access Memory  
=> 실행할 프로그램의 명령어와 데이터가 저장됨  
{{< /callout >}}  

<br>

## **RAM의 특징**
- 실행할 프로그램의 명령어, 데이터가 저장됨  
- 전원을 끄면 RAM에 저장된 명령어와 데이터가 모두 날아감  

### **휘발성 저장 장치 (volatile memory)**  
전원을 끄면 저장된 내용이 사라지는 저장장치

{{< callout type="info" >}}  
**비휘발성 저장 장치 (non-volatile memory)**  
전원이 꺼져도 저장된 내용이 유지되는 저장장치  
=> HDD, SSD, CD-ROM, USB, ...  
{{< /callout >}}  

{{< callout type="info" >}}  
보조기억장치는 전원을 꺼도 내용을 유지하지만 CPU는 보조기억장치에 직접 접근할 수 없음  

그래서 일반적으로,  
비휘발성 저장 장치에는 '보관할 대상'을 저장  
휘발성 저장장치에는 '실행할 대상'을 저장

=> CPU가 실행하려는 프로그램이 보조기억장치에 있다면 이를 RAM으로 복사해서 저장한 뒤 실행  
{{< /callout >}}  

<br>

## **RAM의 용량과 성능**
RAM 용량이 적으면 보조기억장치에서 실행할 프로그램을 가져오는 일이 잦아 실행 시간이 길어짐  
RAM 용량이 크면 보조기억장치에서 많은 데이터를 가져와 미리 RAM에 저장할 수 있어 많은 프로그램을 동시에 빠르게 실행할 수 있음  

=> RAM 용량이 일정 수준 이상 증가한 이후에는 속도가 용량 증가폭에 비례해 증가하지는 않음

<br>

## **RAM의 종류**  

### **DRAM (Dynamic RAM)**  
저장된 데이터가 독적으로 변하는 RAM  
(시간이 지나면 저장된 데이터가 점차 사라지는 RAM)  
=> 데이터의 소멸을 막기 위해 일정 주기로 데이터를 다시 재활성화(다시 저장) 해야함  

{{< callout type="info" >}}  
**장점**  
- 소비 전력이 비교적 낮음  
- 저령함  
- 집적도가 높아 대용량으로 설계하기 유리  

**단점**  
- 데이터의 소멸을 막기 위해 일정 주기로 데이터를 다시 재활성화(다시 저장) 해야함  

=> 일반적으로 메모리로써 사용하는 RAM = DRAM  
{{< /callout >}}  

<hr>

### **SRAM (Static RAM)**  
저장된 데이터가 변하니 않는 RAM  
(시간이 지나도 저장된 데이터가 사라지지 않는 RAM)  

{{< callout type="info" >}}  
메모리로 사용되는 RAM은 SRAM이 아닌 DRAM임  
=> SRAM은 메모리가 아닌 '대용량으로 만들어질 필요는 없지만 속도가 빨라야하는 저장 장치', 캐시 메모리에서 사용됨  

|     | DRAM | SRAM |
|-----|------|------|
|재충전|필요 O|필요 X|
|속도|느림|빠름|
|가격|저렴함|비쌈|
|집적도|높움|낮음|
|소비 전력|적음|높음|
|사용 용도|주기억장치(RAM)|캐시 메모리|

{{< /callout >}}  

<hr>

### **SDRAM (Synchronous Dynamic RAM)**  
클럭 신호와 동기화된, 발전된 형태의 DRAM  
(클럭 타이밍에 맞춰 CPU와 정보를 주고받을 수 있음)  
=> SDRAM은 클럭에 맞춰 동작하며 클럭마다 CPU와 정보를 주고받을 수 있는 DRAM  

<hr>

### **DDR SDRAM (Double Data Rate SDRAM)**  
대역폭을 넓혀 속도를 빠르게 만든 SDRAM  
=> 한 클럭에 두 번씩 CPU와 데이터를 주고 받을 수 있어 단일 SDRAM에 비해 속도가 두배가량 빠름  
(대역폭(data rate) : 데이터를 주고 받는 길의 너비)  

{{< callout type="info" >}}  
DDR SDRAM은 대역폭 크기에 따라 다른 이름으로 불림  
=> 대역폭 수가 늘어날수록 이전 메모리에 비해 2배 넓은 대역폭을 가짐  

**SDR SDRAM(Single Data Rate SDRAM)**  
=> 한 클럭 당 하나씩 데이터를 주고받는 SDRAM  
**DDR SDRAM**  
=> SDR SDRAM보다 대역폭이 2배 높은 SDRAM  
**DDR2 SDRAM**   
**DDR3 SDRAM**  
**DDR4 SDRAM**  
=> 현재 많이 사용중인 메모리 칩셋으로 SDR SDRAM보다 16배 넓은 대역폭을 가짐   
**DDR5 SDRAM**  
=> 가장 최신에 나온 메모리 칩셋으로 DDR4 SDRAM보다 2배, SDR SDRAM에 비해 32배 넓은 대역폭을 가짐  

<br>

=> 최근 가장 흔히 사용되는 RAM  
{{< /callout >}}  
 

<br>
<hr>

# **메모리의 주소 공간**
2종류의 주소 => 물리 주소, 논리 주소   

## **물리 주소와 논리 주소**
### **물리 주소(physical address)**  
실제 하드웨어적인 메모리 주소, RAM에서 실제 데이터가 저장되는 위치를 가리킴  
=> 각 메모리 셀은 고유한 물리적 주소를 갖고 있으며, 이 주소를 통해 직접 데이터에 접근할 수 있음  

<hr>

### **논리 주소(logical address)**  
프로그램이나 CPU에서 사용되는 주소, 프로그램은 논리주소를 사용하여 메모리에 접근(프로그램이 사용하는 가상적인 주소)  
=> 운영체제의 메모리 관리 유닛(MMU)은 이 논리주소를 물리주소로 변환하여 실제 메모리 위치를 찾아내어 데이터에 접근할 수 있게 해줌  

<hr>

### **논리 주소와 물리 주소 간의 변환**  
**메모리 관리 장치 (Memory Management Unit, MMU)**  
논리 주소와 물리 주소간 변환을 해주는 장치(CPU와 주소 버스 사이에 위치)  

{{< callout type="info" >}}  
CPU가 발생 시킨 논리 주소에 베이스 레지스터 값을 더하여 논리 주소를 물리 주소로 변환  
> CPU 발생 논리주소 100 + MMU 베이스 레지스터 15000  
> => 물리 주소 15100 (RAM = 15100번지)  

**논리 주소**  
프로그램의 시작점으로부터 떨어진 거리를 표시  

**베이스 레지스터**  
프로그램의 가장 작은 물리 주소(프로그램의 첫 물리 주소)를 저장  
=> 프로그램 논리 주소 0번지의 물리적 위치를 의미  
{{< /callout >}}  

<br>

## **메모리 보호 기법**  
다른 프로그램 영역을 침범할 수 있는 명령어는 위험하기 때문에 논리 주소 범위를 벗어나는 명령어 실행을 방지하고, 실행 중인 프로그램이 다른 프로그램에 영향 받지 않게 보호할 방법이 필요   

### **한계 레지스터**  
논리 주소의 최대 크기를 저장하는 레지스터, CPU 명령이 프로그램 주소 범위를 벗어나는 경우를 방지하는 장치  

{{< callout type="info" >}}  
**프로그램의 물리 주소 범위**  
베이스 레지스터 값 이상, 베이스레지스터 값 + 한계 레지스터 값 미만  

CPU가 접근하는 논리 주소는 한계 레지스터가 저장한 값보다 커서는 안됨  
=> 한계 레지스터 보다 높은 주소 값에 접근하는 것은 곧 프로그램의 범위에 벗어난 메모리 공간에 접근하는 것과 같기 때문
{{< /callout >}}  

#### **보호 과정**
접근하고자 하는 논리 주소가 한계 레지스터보다 작은지를 검사함으로써 메모리 내의 프로그램을 보호할 수 있음  

1. CPU는 메모리에 접근하기 전에 접근하고자 하는 논리 주소가 한계 레지스터보다 작은지를 항상 검사  
2. 만약 CPU가 한계 레지스터보다 높은 논리 주소에 접근하려고 하면 인터럽트(트랩)을 발생시켜 프로그램 실행을 중단  
3. 범위 내의 값이라면 논리주소를 물리 주소로 변환하여 메모리에 접근
      
=> 이러한 방식으로 실행 중인 프로그램의 독립적인 실행 공간을 확보하고 하나의 프로그램이 다른 프로그램을 침범하지 못하게 보호할 수 있음  


<br>
<hr>

# **캐시 메모리**
CPU가 메모리에 접근하는 시간은 CPU의 연산 속도보다 느림  
=> CPU가 연산을 빨리 한다 해도 메모리에 접근하는 시간이 느리면 CPU의 빠른 연산 속도는 쓸모가 없어짐  
=> 이를 극복하기 위한 저장 장치 = 캐시 메모리  

<br>

## **저장 장치 계층 구조**  
**(Memory Hierarchy)**  
컴퓨터가 사용하는 저장 장치들은 'CPU에 얼마나 가까운가'를 기준으로 계층적으로 나타낼 수 있음  

|저장 장치|속도|용량|가격|
|---------|----|----|----|
|레지스터|빠름|작음|비쌈|
|캐시 메모리|-|-|-|
|메모리|-|-|-|
|보조기억장치|느림|큼|저렴함|

<br>

## **캐시 메모리**
**(Cash Memory)**  
CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치  

{{< callout type="info" >}}  
캐시 메모리는 CPU의 연산 속도와 메모리 접근 속도의 차이를 조금이나마 줄이기 위해 탄생  
=> CPU가 매번 메모리에 왔다 갔다 하는 건 시간이 오래 걸리니, 메모리에서 CPU가 사용할 일부 데이터를 미리 캐시 메모리로 가지고 와서 활용  
{{< /callout >}}  

<br>

### **캐시 메모리의 종류**  
CPU(코어)와 가까운 순대로 여러 개의 캐시 메모리가 계층을 구성

**L1 (level 1) 캐시** : 코어와 가장 가까운 캐시 메모리  
**L2 (level 2) 캐시**  
**L3 (level 3) 캐시**  
=> 일반적으로 L1과 L2는 코어 내부에, L3는 코어 외부에 존재

#### **캐시 메모리별 특징**  
L1과 L2 캐시는 코어마다 고유한 캐시 메모리로 할당  
L3 캐시는 여러 코어가 하나의 L3를 공유하는 형태로 사용  

| 항목 | 비교 |
|------|------|
|용량|L1 < L2 < L3|
|속도|L1 > L2 > L3|
|가격|L1 > L2 > L3|

<br>

### **분리형 캐시 (split cache)**
코어와 가장 가까운 L1 캐시의 접근 속도를 조금이라도 빠르게 만들기 위해 L1 캐시를 분리한 것  
명령어만을 저장하는 L1 캐시 = L1I(Level 1 Instruction) 캐시  
데이터만을 저장하는 L1 캐시 = L1D(Level 1 Data) 캐시  

<br>

## **참조 지역성 원리**
캐시 메모리는 CPU가 사용할 법한 대상을 예측해서 저장  
=> 캐시메모리는 참조 지역성의 원리에 입각해 CPU가 사용할 데이터를 예측  
- CPU는 최근에 접근한 메모리 공간에 다시 접근하는 경향이 있음  
- CPU는 접근한 메모리 공간 근처를 접근하는 경향이 있음  

### **최근에 접근했던 메모리 공간에 다시 접근하는 경향**  
**시간 지역성 (temporal locality)**  
최근에 접근했던 메모리 공간에 다시 접근하려는 경향  
=> 프로그래밍에서 변수를 저장하고, 변수를 자주 참조하듯이, CPU 역시 최근에 접근한 메모리 공간을 여러번 참조(접근)하려는 경향이 있음

### **접근한 메모리 공간 근처를 접근하는 경향**  
**공간 지역성 (spatial locality)**  
접근한 메모리 공간 근처를 접근하는 경향  
=> 프로그램을 실행하는데 필요한 데이터들은 보통 관련 데이터들끼리 메모리 공간에 모여있기 때문에 접근했던 메모리 공간 근처를 접근하려는 경향이 있음  

### **캐시 히트 (cache hit)**  
자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용된 경우  

### **캐시 미스 (cache miss)**
자주 사용될 것으로 예측하여 캐시 메모리에 저장했지만, 예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우  
=> 캐시 미스가 자주 발생하면 CPU가 필요한 데이터를 메모리에서 가져오는 경우가 많아지기 때문에 성능이 떨어짐  

### **캐시 적중률 (cache hit ratio)**  
캐시가 히트되는 비율  

{{< callout type="info" >}}  
캐시 적중률 = 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)   
=> 우리가 사용하는 컴퓨터의 캐시 적중률은 대략 85% ~ 95% 이상  
{{< /callout >}}  

{{< callout type="info" >}}  
캐시 메모리의 이점을 제대로 활용하기 위해서는 캐시 적중률을 높이는 것이 중요  
=> 캐시메모리는 참조 지역성의 원리에 입각해 CPU가 사용할 데이터를 예측  
{{< /callout >}}  

<br>
<hr>

> 참고  
> [혼자 공부하는 컴퓨터 구조+운영체제 (책)](https://hongong.hanbit.co.kr/%EC%BB%B4%ED%93%A8%ED%84%B0-%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/)  
> [혼자 공부하는 컴퓨터 구조+운영체제 (강의)](https://www.inflearn.com/course/%ED%98%BC%EC%9E%90-%EA%B3%B5%EB%B6%80%ED%95%98%EB%8A%94-%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C)


